# Reverse Abliteration: Advanced Technique for AI Model ModificationğŸ§ ğŸ”§

[![PyPI version](https://badge.fury.io/py/reverse-abliterator.svg)](https://badge.fury.io/py/reverse-abliterator)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub issues](https://img.shields.io/github/issues/leoleojames1/reverse-abliterator)](https://github.com/leoleojames1/reverse-abliterator/issues)

## Introduction ğŸŒŸ

This project explores abliteration and reverse abliteration, two innovative techniques for modifying pre-trained language models. These methods offer targeted approaches to altering model behavior, complementing traditional fine-tuning techniques. This tool is a reverse construction of FailSpy's abliterator repo which you can check out here:
[FailSpy/abliterator](https://github.com/FailSpy/abliterator)

## Core Concepts ğŸ’¡

1. Abliteration suppresses the desired style directions.
2. Reverse Abliteration amplifies the desired style directions.

### Abliteration ğŸš«

Abliteration is designed to selectively suppress specific behaviors or capabilities of a language model while preserving its overall functionality.

Key features:
- Aims to reduce or eliminate undesired outputs or behaviors ğŸ›‘
- Modifies model weights by subtracting projections along refusal directions in the model's activation space ğŸ“‰
- Preserves general model capabilities while targeting specific behaviors for suppression ğŸ¯

### Reverse Abliteration ğŸ”„

Reverse abliteration, conversely, aims to enhance or amplify certain behaviors or capabilities of a language model.

Key features:
- Seeks to strengthen or improve specific desired outputs or behaviors ğŸ“ˆ
- Modifies model weights by adding projections along style or enhancement directions in the model's activation space ğŸ”¼
- Enhances targeted capabilities while aiming to minimally impact other functionalities ğŸ­

## Mechanism âš™ï¸

Both techniques leverage a similar process:

1. Activation Caching: Run instructions through the model and store activations at specified layers. ğŸ’¾
2. Direction Calculation: Compute the difference between mean activations of target and baseline instructions. ğŸ§®
3. Weight Modification: Modify model weights by projecting onto calculated directions. ğŸ”§
4. Iterative Refinement: Apply modifications iteratively, testing performance after each step. ğŸ”

The key difference lies in the final step:
- Abliteration subtracts the projection to suppress behaviors â–
- Reverse abliteration adds the projection to enhance behaviors â•

## Comparison with Traditional Fine-tuning ğŸ”

1. Granularity:
   - Fine-tuning: Broad adjustment of model behavior ğŸŒŠ
   - Abliteration/Reverse Abliteration: Targeted modification of specific behaviors ğŸ¯

2. Data Requirements:
   - Fine-tuning: Substantial dataset for the target task ğŸ“š
   - Abliteration/Reverse Abliteration: Can work with smaller, curated datasets ğŸ“Š

3. Computational Efficiency:
   - Fine-tuning: Often computationally intensive ğŸ–¥ï¸ğŸ’¨
   - Abliteration/Reverse Abliteration: Can be more efficient, focusing on specific components âš¡

4. Preservation of Capabilities:
   - Fine-tuning: Risk of catastrophic forgetting ğŸ§ ğŸ’¨
   - Abliteration/Reverse Abliteration: Designed to preserve general capabilities ğŸ›¡ï¸

5. Interpretability:
   - Fine-tuning: Changes can be difficult to interpret ğŸ•µï¸â€â™€ï¸
   - Abliteration/Reverse Abliteration: More targeted and potentially more interpretable modifications ğŸ”¬

## Applications ğŸš€

### Abliteration:
- Reducing biases and harmful outputs ğŸš¯
- Creating "safer" versions of models ğŸ›¡ï¸
- Consistently avoiding certain types of outputs ğŸš«

### Reverse Abliteration:
- Enhancing specific skills (e.g., mathematical reasoning, creative writing) ğŸ§®âœï¸
- Specializing models for particular domains ğŸ‘©â€âš•ï¸ğŸ‘¨â€ğŸ’¼ğŸ‘©â€ğŸ”¬
- Injecting specific writing styles or personas ğŸ­
- Improving emotional intelligence in responses ğŸ¤—
- Adapting models to new tasks or contexts quickly ğŸ¦¾

## Advantages and Limitations âš–ï¸

Advantages:
- Targeted modifications with potential for better interpretability ğŸ¯ğŸ”
- Computational efficiency compared to full fine-tuning âš¡
- Potential for better preservation of general capabilities ğŸ›¡ï¸

Limitations:
- Requires careful identification of relevant directions ğŸ§­
- Potential for unexpected side effects ğŸ²
- Less suitable for broad changes to model behavior ğŸŒŠ

## Considerations ğŸ¤”

1. Stability and Generalization: Enhancements may lead to overfitting or unexpected effects. ğŸŒ‹
2. Ethical Implications: Rapid behavior modification raises important ethical questions. ğŸ§‘â€âš–ï¸
3. Validation and Testing: Robust frameworks are crucial for ensuring reliability and safety. ğŸ§ª
4. Theoretical Foundations: Further research is needed on how these modifications affect internal representations. ğŸ“šğŸ”¬
5. Combination with Other Techniques: Potential for powerful hybrid approaches with other training methods. ğŸ§©

## Conclusion ğŸŒŸ

Abliteration and reverse abliteration represent sophisticated approaches to selectively modifying language model behavior. By offering more targeted and potentially more efficient ways to adjust model behavior, these methods open up new possibilities for customizing and improving AI systems. As research progresses, these techniques may lead to more adaptable, specialized, and capable AI models, while also presenting important challenges in terms of stability, ethics, and validation that need careful consideration.

These innovative approaches complement traditional fine-tuning, offering a spectrum of model modification techniques that can be tailored to specific needs and constraints. As the field of AI continues to evolve, abliteration and reverse abliteration stand as promising tools for creating more nuanced and controllable AI systems. ğŸš€ğŸ¤–

## Installation

You can install the Reverse Abliterator package using pip:

```
pip install reverseAbliterator
```

## Usage

Here's a basic example of how to use the Reverse Abliterator:

```python
from reverseAbliterator import ReverseAbliterator

model_path = "path/to/your/model"
target_instructions = ["Write a poem about nature", "Explain quantum physics"]
baseline_instructions = ["Hello", "What's the weather like?"]

ra = ReverseAbliterator(
    model=model_path,
    dataset=([target_instructions, baseline_instructions]),
    device="cuda" if torch.cuda.is_available() else "cpu"
)

ra.cache_activations(N=len(target_instructions), batch_size=1)
initial_enhancement = ra.measure_enhancement()
print("Initial enhancement score:", initial_enhancement)

ra.enhance_model(strength=0.1)
post_enhancement = ra.measure_enhancement()
print("Post-enhancement score:", post_enhancement)

ra.test_enhancement(N=2, max_tokens_generated=30)

# Save the modified model
ra.save_modified_model("path/to/save/modified_model.pth")
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

